{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import editdistance\n",
    "import datetime\n",
    "\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "from spacy.vocab import Vocab\n",
    "\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spellChecker(object):\n",
    "    \"\"\"Class object for Out Of Vocabulary(OOV) corrections \n",
    "    \"\"\"\n",
    "    name = \"contextual spellchecker\"\n",
    "\n",
    "    def __init__(self, vocab_path='./data/vocab.txt',debug=False):\n",
    "        # self.nlp = spacy.load(\n",
    "        #     \"en_core_web_sm\", disable=[\"tagger\", \"parser\"]\n",
    "        # )  # using default tokeniser with NER\n",
    "        with open(vocab_path) as f:\n",
    "            # if want to remove '[unusedXX]' from vocab\n",
    "            # words = [line.rstrip() for line in f if not line.startswith('[unused')]\n",
    "            words = [line.rstrip() for line in f]\n",
    "        self.vocab = Vocab(strings=words)\n",
    "        self.BertTokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "        self.BertModel = AutoModelWithLMHead.from_pretrained(\"bert-base-cased\")\n",
    "        self.mask = self.BertTokenizer.mask_token\n",
    "        self.debug = debug\n",
    "        if not Doc.has_extension('contextual_spellCheck'):\n",
    "            Doc.set_extension('contextual_spellCheck', default=True)\n",
    "            Doc.set_extension('performed_spellCheck', default=False)\n",
    "\n",
    "            # {originalToken-1:[suggestedToken-1,suggestedToken-2,..],\n",
    "            #  originalToken-2:[...]}\n",
    "            Doc.set_extension('suggestions_spellCheck', getter=self.doc_suggestions_spellCheck)\n",
    "            Doc.set_extension('outcome_spellCheck', default=\"\")\n",
    "            Doc.set_extension('score_spellCheck', default=None)\n",
    "\n",
    "            Span.set_extension('get_has_spellCheck', getter=self.span_require_spellCheck)\n",
    "            Span.set_extension('score_spellCheck', getter=self.span_score_spellCheck)\n",
    "\n",
    "            Token.set_extension('get_require_spellCheck', getter=self.token_require_spellCheck)\n",
    "            Token.set_extension('get_suggestion_spellCheck', getter=self.token_suggestion_spellCheck)\n",
    "            Token.set_extension('score_spellCheck', getter=self.token_score_spellCheck)\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        if self.debug: modelLodaded = datetime.datetime.now()\n",
    "        misspellTokens, doc = self.misspellIdentify(doc)\n",
    "        if self.debug: modelLoadTime = self.timeLog(\"Misspell identification: \",modelLodaded)\n",
    "        if len(misspellTokens) > 0:\n",
    "            candidate = self.candidateGenerator(doc, misspellTokens)\n",
    "            if self.debug: modelLoadTime = self.timeLog(\"candidate Generator: \",modelLodaded)\n",
    "            answer = self.candidateRanking(candidate)\n",
    "            if self.debug: modelLoadTime = self.timeLog(\"candidate ranking: \",modelLodaded)\n",
    "            updatedQuery = \"\"\n",
    "            for i in doc:\n",
    "                if i.i in [misspell.i for misspell in misspellTokens]:\n",
    "                    updatedQuery += answer[i] + i.whitespace_\n",
    "                else:\n",
    "                    updatedQuery += i.text_with_ws\n",
    "\n",
    "            if self.debug: print(\"Did you mean: \", updatedQuery)\n",
    "            doc._.set(\"outcome_spellCheck\",updatedQuery)\n",
    "        return doc\n",
    "\n",
    "\n",
    "    def check(self, query=\"\"):\n",
    "        \"\"\"Complete pipeline which returns update query\n",
    "\n",
    "        Keyword Arguments:\n",
    "            query {str} -- User query for which spell checking to be done (default: {''})\n",
    "\n",
    "        Returns:\n",
    "            {str} -- returns updated query with spelling corrections (if any)\n",
    "        \"\"\"\n",
    "        if type(query) != str and len(query) == 0:\n",
    "            return (\"Invalid query, expected non empty `str` but passed\", query)\n",
    "\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"])\n",
    "        doc = nlp(query)\n",
    "        modelLodaded = datetime.datetime.now()\n",
    "        misspellTokens, doc = self.misspellIdentify(doc)\n",
    "        modelLoadTime = timeLog(\"Misspell identification: \",modelLodaded)\n",
    "        if len(misspellTokens) > 0:\n",
    "            candidate = self.candidateGenerator(doc, misspellTokens)\n",
    "            answer = self.candidateRanking(candidate)\n",
    "            updatedQuery = \"\"\n",
    "            for i in doc:\n",
    "                if i in misspellTokens:\n",
    "                    updatedQuery += answer[i] + i.whitespace_\n",
    "                else:\n",
    "                    updatedQuery += i.text_with_ws\n",
    "\n",
    "            print(\"Did you mean: \", updatedQuery)\n",
    "            doc._.set(\"outcome_spellCheck\",updatedQuery)\n",
    "            # problem with below as it modifies the original object\n",
    "#             with doc.retokenize() as retokenizer:\n",
    "#                 print(\"Original text:\",retokenizer.merge(doc[:]))\n",
    "        return updatedQuery, doc\n",
    "\n",
    "    def misspellIdentify(self, doc,query=\"\"):\n",
    "        \"\"\"To identify misspelled words from the query\n",
    "\n",
    "        At present, All the following criteria should be met for word to be misspelled\n",
    "        1. Should not in our vocab\n",
    "        2. should not be a Person\n",
    "        3. Should not be a number\n",
    "\n",
    "\n",
    "        Keyword Arguments:\n",
    "            query {str} -- user query eg: \"aa bb cc...\" (default: {''})\n",
    "\n",
    "        Returns:\n",
    "            {tuple} -- returns `List[`Token`]` and `Doc`\n",
    "        \"\"\"\n",
    "\n",
    "        # doc = self.nlp(query)\n",
    "        misspell = []\n",
    "        for token in doc:\n",
    "            if (\n",
    "                (token.text.lower() not in self.vocab)\n",
    "                and (token.ent_type_ != \"PERSON\")\n",
    "                and (not token.like_num)\n",
    "                and (not token.like_email)\n",
    "                and (not token.like_url)                \n",
    "            ):\n",
    "\n",
    "                misspell.append(token)\n",
    "\n",
    "        if self.debug:\n",
    "            print(misspell)\n",
    "        return (misspell, doc)\n",
    "\n",
    "    def candidateGenerator(self, doc, misspellings, top_n=10):\n",
    "        \"\"\"Returns Candidates for misspells\n",
    "\n",
    "        This function is responsible for generating candidate list for misspell\n",
    "        using BERT. The misspell is masked with a token and the model tries to \n",
    "        predict `n` candidates for the mask.\n",
    "\n",
    "        Arguments:\n",
    "            misspellings {List[`Token`]} -- Contains List of `Token` object types \n",
    "            from spacy to preserve meta information of the token \n",
    "\n",
    "        Keyword Arguments:\n",
    "            top_n {int} -- Number of candidates to be generated (default: {5})\n",
    "            query {User query} -- This is used for context pwered candidate generations.  (default: {''})\n",
    "\n",
    "        Returns:\n",
    "            Dict{`Token`:List[{str}]} -- Eg of return type {misspell-1:['candidate-1','candidate-2', ...],\n",
    "                            misspell-2:['candidate-1','candidate-2'. ...]}\n",
    "        \"\"\"\n",
    "\n",
    "        response = {}\n",
    "        score = {}\n",
    "\n",
    "        for token in misspellings:\n",
    "            updatedQuery = \"\"\n",
    "            for i in doc:\n",
    "                if (i.i == token.i):\n",
    "                    updatedQuery += self.mask + i.whitespace_\n",
    "                else:\n",
    "                    updatedQuery += i.text_with_ws\n",
    "            if self.debug:\n",
    "                print(\n",
    "                    \"For\", \"`\" + token.text + \"`\", \"updated query is:\\n\", updatedQuery\n",
    "                )\n",
    "\n",
    "            model_input = self.BertTokenizer.encode(updatedQuery, return_tensors=\"pt\")\n",
    "            mask_token_index = torch.where(\n",
    "                model_input == self.BertTokenizer.mask_token_id\n",
    "            )[1]\n",
    "            token_logits = self.BertModel(model_input)[0]\n",
    "            mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "            token_probability = torch.nn.functional.softmax(mask_token_logits,dim=1)\n",
    "            top_n_score, top_n_tokens = torch.topk(token_probability, top_n, dim=1)\n",
    "            top_n_tokens = top_n_tokens[0].tolist()\n",
    "            top_n_score = top_n_score[0].tolist()\n",
    "            if self.debug:\n",
    "                print(\"top_n_tokens:\", top_n_tokens)\n",
    "                print(\"token_score: \", top_n_score)\n",
    "\n",
    "            if token not in response:\n",
    "                response[token] = [\n",
    "                    self.BertTokenizer.decode([candidateWord])\n",
    "                    for candidateWord in top_n_tokens\n",
    "                ]\n",
    "                score[token]=[(self.BertTokenizer.decode([top_n_tokens[i]]),round(top_n_score[i],5)) for i in range(top_n)]\n",
    "\n",
    "            # for candidate in top_5_tokens:\n",
    "            # response[token].append(self.BertTokenizer.decode([candidate]))\n",
    "            # print(updatedQuery.replace(self.mask, self.BertTokenizer.decode([candidate])))\n",
    "\n",
    "            if self.debug: print(\"\\nresponse: \",response,\"\\nscore: \",score)\n",
    "\n",
    "        doc._.set(\"performed_spellCheck\",True)\n",
    "        doc._.set(\"score_spellCheck\",score)\n",
    "        \n",
    "\n",
    "        return response\n",
    "\n",
    "    def candidateRanking(self, misspellingsDict):\n",
    "        \"\"\"Ranking the candidates based on edit Distance\n",
    "\n",
    "        At present using a library to calculate edit distance \n",
    "        between actual word and candidate words. Candidate word \n",
    "        for which edit distance is lowest is selected. If least \n",
    "        edit distance is same then word with higher probability \n",
    "        is selected by default\n",
    "\n",
    "        Arguments:\n",
    "            misspellingsDict {Dict{`Token`:List[{str}]}} -- \n",
    "            Orginal token is the key and candidate words are the values \n",
    "\n",
    "        Returns:\n",
    "            Dict{`Token`:{str}} -- Eg of return type {misspell-1:'BEST-CANDIDATE'}\n",
    "        \"\"\"\n",
    "\n",
    "        response = {}\n",
    "        #         doc = self.nlp(query)\n",
    "        for misspell in misspellingsDict:\n",
    "            ## Init least_edit distance\n",
    "            least_edit_dist = 100\n",
    "\n",
    "            if self.debug:\n",
    "                print(\"misspellingsDict[misspell]\", misspellingsDict[misspell])\n",
    "            for candidate in misspellingsDict[misspell]:\n",
    "                edit_dist = editdistance.eval(misspell.text, candidate)\n",
    "                if edit_dist < least_edit_dist:\n",
    "                    least_edit_dist = edit_dist\n",
    "                    response[misspell] = candidate\n",
    "\n",
    "            if self.debug:\n",
    "                print(response)\n",
    "        return response\n",
    "    \n",
    "    def timeLog(self, fnName, relativeTime):\n",
    "        \"\"\"For time log\n",
    "\n",
    "        Arguments:\n",
    "            fnName {str} -- function name to print\n",
    "            relativeTime {datetime} -- previous date time for subtraction\n",
    "\n",
    "        Returns:\n",
    "            datetime -- datetime of current logging\n",
    "        \"\"\"\n",
    "\n",
    "        timeNow = datetime.datetime.now()\n",
    "        print(fnName, \"took: \", timeNow - relativeTime)\n",
    "        return datetime.datetime.now()\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    def token_require_spellCheck(self,token):\n",
    "        \"\"\"Getter for Token attributes. \n",
    "        @Returns True if the token requires spellCheck\n",
    "        \"\"\"\n",
    "        return any([token.i == suggestion.i \n",
    "                    for suggestion in token.doc._.suggestions_spellCheck.keys()])\n",
    "    \n",
    "    def token_suggestion_spellCheck(self,token):\n",
    "        \"\"\"Getter for Token attributes. \n",
    "        @Returns    [] or List['suggestion-1','suggestion-1',...] \n",
    "                    \n",
    "        \"\"\"\n",
    "        for suggestion in token.doc._.suggestions_spellCheck.keys():\n",
    "            if token.i == suggestion.i:\n",
    "                return token.doc._.suggestions_spellCheck[token]\n",
    "        return []\n",
    "    \n",
    "    def token_score_spellCheck(self, token):\n",
    "        \"\"\"Getter for Token attributes. \n",
    "        @Returns    [] or List[('suggestion-1',score-1), ('suggestion-1',score-2), ...] \n",
    "                    \n",
    "        \"\"\"   \n",
    "        if token.doc._.score_spellCheck is None:\n",
    "            return []  \n",
    "        for suggestion in token.doc._.score_spellCheck.keys():\n",
    "            if token.i == suggestion.i:\n",
    "                return [token.doc._.score_spellCheck[token]]\n",
    "        return []\n",
    "\n",
    "        \n",
    "    def span_score_spellCheck(self, span):\n",
    "        return [{token:self.token_score_spellCheck(token)} for token in span]\n",
    "        \n",
    "    \n",
    "    def span_require_spellCheck(self,span):\n",
    "        \"\"\"Getter for Token attributes. \n",
    "        @Returns True if the span requires spellCheck\n",
    "        \"\"\"\n",
    "        return any([self.token_require_spellCheck(token) for token in span])\n",
    "    \n",
    "    def doc_suggestions_spellCheck(self,doc):\n",
    "        response={}\n",
    "        if doc._.score_spellCheck is None:\n",
    "            return response\n",
    "        for token in doc._.score_spellCheck:\n",
    "            if token not in response:\n",
    "                response[token]=[]\n",
    "            for suggestion_score in doc._.score_spellCheck[token]:\n",
    "                response[token].append(suggestion_score[0])       \n",
    "        return response\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\"])\n",
    "checker = spellChecker(debug=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean:  My sister has a dog. She loves him.\n",
      "==================== Doc Extention Test ====================\n",
      "True\n",
      "True\n",
      "{nim: ['dogs', 'it', 'me', 'cats', 'you', 'him', 'animals', 'them', 'horses', 'kids']}\n",
      "My sister has a dog. She loves him.\n",
      "{nim: [('dogs', 0.34339), ('it', 0.17349), ('me', 0.06944), ('cats', 0.06866), ('you', 0.04385), ('him', 0.03943), ('animals', 0.02735), ('them', 0.02059), ('horses', 0.01483), ('kids', 0.01346)]}\n",
      "==================== Token Extention Test ====================\n",
      "False\n",
      "[]\n",
      "[]\n",
      "==================== Span Extention Test ====================\n",
      "False\n",
      "[{My: []}, {sister: []}, {has: []}, {a: []}]\n",
      "['ner', 'contextual spellchecker']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('contextual spellchecker', <__main__.spellChecker at 0x12c44f150>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(checker)\n",
    "# nlp.add_pipe(checker,name = \"contextual spellchecker\")\n",
    "# checker.add_to_pipe(nlp)\n",
    "\n",
    "doc = nlp(u'My sister has a dog. She loves nim.')\n",
    "\n",
    "\n",
    "print(\"=\"*20,\"Doc Extention Test\", \"=\"*20)\n",
    "print(doc._.contextual_spellCheck)\n",
    "print(doc._.performed_spellCheck)\n",
    "print(doc._.suggestions_spellCheck)\n",
    "print(doc._.outcome_spellCheck)\n",
    "print(doc._.score_spellCheck)\n",
    "\n",
    "token_pos =2\n",
    "print(\"=\"*20,\"Token Extention Test\", \"=\"*20)\n",
    "print(doc[token_pos]._.get_require_spellCheck)\n",
    "print(doc[token_pos]._.get_suggestion_spellCheck)\n",
    "print(doc[token_pos]._.score_spellCheck)\n",
    "\n",
    "span_start = token_pos-2\n",
    "span_end = token_pos+2\n",
    "print(\"=\"*20,\"Span Extention Test\", \"=\"*20)\n",
    "print(doc[span_start:span_end]._.get_has_spellCheck)\n",
    "print(doc[span_start:span_end]._.score_spellCheck)\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "nlp.remove_pipe(\"contextual spellchecker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=datetime.datetime.now()\n",
    "# checker = spellChecker(debug=True)\n",
    "# modelLoadTime = timeLog(\"Model Loading\",start)\n",
    "\n",
    "# query = \"Income was $9.4 milion compared to the prior year of $2.7 milion.\"\n",
    "\n",
    "# (updatedQuery, doc) = checker.check(query)\n",
    "# checkerTime = timeLog('Sentence Correction', modelLoadTime)\n",
    "\n",
    "\n",
    "# misspellTokens = checker.misspellIdentify()\n",
    "# misspellTime = timeLog(\"Misspell indetifying\", modelLoadTime)\n",
    "\n",
    "# candidate = checker.candidateGenerator(misspellTokens)\n",
    "# candidateTime = timeLog(\"CandidateGeneration\",misspellTime)\n",
    "\n",
    "# answer = checker.candidateRanking(candidate)\n",
    "# timeLog(\"ranking\",candidateTime)\n",
    "# for key in answer:\n",
    "#     print('wrong spelling: ','`'+key.text+'`',\"-- best candidate:\", '`'+answer[key]+'`')\n",
    "# print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             Doc.set_extension('contextual_spellCheck', default=True)\n",
    "#             Doc.set_extension('performed_spellCheck', default=False)\n",
    "\n",
    "#             # {originalToken-1:[suggestedToken-1,suggestedToken-2,..],\n",
    "#             #  originalToken-2:[...]}\n",
    "#             Doc.set_extension('suggestions_spellCheck', default=None)\n",
    "#             Doc.set_extension('outcome_spellCheck', default=\"\")\n",
    "#             Doc.set_extension('score_spellCheck', default=None)\n",
    "\n",
    "#             Span.set_extension('get_has_spellCheck', getter=self.span_require_spellCheck)\n",
    "#             Span.set_extension('score_spellCheck', getter=self.span_score_spellCheck)\n",
    "\n",
    "#             Token.set_extension('get_require_spellCheck', getter=self.token_require_spellCheck)\n",
    "#             Token.set_extension('get_suggestion_spellCheck', getter=self.token_suggestion_spellCheck)\n",
    "#             Token.set_extension('score_spellCheck', getter=self.token_score_spellCheck)\n",
    "# #             Token.set_extension('score_spellCheck', default=1.0)\n",
    "\n",
    "\n",
    "print(\"=\"*20,\"Doc Extention Test\", \"=\"*20)\n",
    "print(doc._.contextual_spellCheck)\n",
    "print(doc._.performed_spellCheck)\n",
    "print(doc._.suggestions_spellCheck)\n",
    "print(doc._.outcome_spellCheck)\n",
    "print(doc._.score_spellCheck)\n",
    "\n",
    "print(\"=\"*20,\"Token Extention Test\", \"=\"*20)\n",
    "print(checker.token_require_spellCheck(doc[len(doc)-2]),doc[len(doc)-2].text)\n",
    "print(doc[len(doc)-2]._.get_require_spellCheck)\n",
    "print(doc[len(doc)-2]._.get_suggestion_spellCheck)\n",
    "print(doc[len(doc)-2]._.score_spellCheck)\n",
    "\n",
    "\n",
    "print(\"=\"*20,\"Span Extention Test\", \"=\"*20)\n",
    "print(checker.token_require_spellCheck(doc[len(doc)-2]),doc[len(doc)-2].text)\n",
    "print(doc[len(doc)-7:len(doc)-1]._.get_has_spellCheck)\n",
    "print(doc[len(doc)-7:len(doc)-1]._.score_spellCheck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[2].is_oov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0.9035419225692749, 0.09310110658407211, 0.0012437802506610751, 0.0006837246473878622, 0.0005358955240808427]\n",
    "a=[round(i,5) for i in a]\n",
    "print(a)\n",
    "\n",
    "b = [(a[i]+1,a[i]) for i in range(5)]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
